import numpy as np
import matplotlib.pyplot as plt

#-----------------------------------------------
#------THIS CODE IS PART A DATASET 1------------
#-----------------------------------------------

# Define the dataset
data = np.array([[2, 10], [2, 5], [8, 4], [5, 8], [7, 5], [6, 4], [1, 2], [4, 9]])
centers = np.array([[2, 5], [8, 4], [4, 9]])
x_data = [2, 2, 8, 5, 7, 6, 1, 4]
y_data = [10, 5, 4, 8, 5, 4, 2, 9]
center_data_x = [2, 8, 4]
center_data_y = [5, 4, 9] 

# Show original plot and center
plt.figure()
plt.scatter(x_data,y_data)
plt.scatter(center_data_x, center_data_y, marker='x', s = 200)
plt.title("original data and center")

# Loop until convergence
converged = False
iteration = 0
while not converged:
    iteration += 1
    clusters = [[] for _ in range(len(centers))]
    
    # Assign each point to the closest cluster
    for point in data:
        distances = np.sqrt(np.sum((centers - point)**2, axis=1))
        closest_center = np.argmin(distances)
        clusters[closest_center].append(point)
    
    # Calculate the new cluster centers
    new_centers = []
    for cluster in clusters:
        new_centers.append(np.mean(cluster, axis=0))
    
    # Check for convergence
    if np.allclose(centers, new_centers):
        converged = True
    else:
        centers = new_centers
    
    # Plot the results
    plt.figure()
    colors = ['r', 'g', 'b']
    for i, cluster in enumerate(clusters):
        for point in cluster:
            plt.scatter(point[0], point[1], color=colors[i])
        plt.scatter(centers[i][0], centers[i][1], color=colors[i], marker='x', s=200)
    plt.xlim(0, 10)
    plt.ylim(0, 10)
    plt.title(f'K-means clustering after iteration {iteration}')
    plt.show()
    print(clusters)
    print(new_centers)
print(f'Converged after {iteration} iterations.')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#-----------------------------------------------
#------THIS CODE IS PART A DATASET 2------------
#-----------------------------------------------

# Load the dataset
url = 'https://raw.githubusercontent.com/tofighi/MachineLearning/master/datasets/heart.csv'
df = pd.read_csv(url)
X = df[['sbp', 'tobacco']].values

X_train = X[:300]
X_test = X[301:]

# Initialize the centroids randomly
np.random.seed(42)
centroids = np.random.rand(2, 2) * X.max(axis=0)

for i in range(10):
    distances = np.sqrt(((X_train - centroids[:, np.newaxis])**2).sum(axis=2))
    labels = np.argmin(distances, axis=0)
    for j in range(2):
        centroids[j] = X_train[labels == j].mean(axis=0)

# Plot the results
plt.figure(figsize=(10, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], c=labels)
plt.scatter(centroids[:, 0], centroids[:, 1], marker='x', s=200, linewidths=3, color='r')
plt.title('KMeans Clustering')
plt.xlabel('sbp')
plt.ylabel('tobacco')
plt.show()

print(centroids)

from sklearn.cluster import KMeans
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
#-----------------------------------------------
#------THIS CODE IS PART D DATASET 1------------
#-----------------KMeans------------------------
#-----------------------------------------------

# Define the dataset
X = [[2, 10], [2, 5], [8, 4], [5, 8], [7, 5], [6, 4], [1, 2], [4, 9]]
init_centers = [[2, 5], [8, 4], [4, 9]]

# Define the KMeans model
kmeans = KMeans(n_clusters=3, init=init_centers, n_init=1)
kmeans.fit(X)
labels = kmeans.labels_
centers = kmeans.cluster_centers_

print("Labels:", labels)
print("Centers:", centers)
print("Number of iterations:", kmeans.n_iter_)

# Plot the data points and the clusters
x_vals = [x[0] for x in X]
y_vals = [x[1] for x in X]
plt.scatter(x_vals, y_vals, c=labels)

for center in kmeans.cluster_centers_:
    plt.scatter(center[0], center[1], marker='x', s=200, linewidths=3, color='b')

# Set the axis limits and labels
plt.xlim(0, 10)
plt.ylim(0, 10)
plt.xlabel('X')
plt.ylabel('Y')
plt.title('KMeans Clustering')
plt.show()

import math
import matplotlib.pyplot as plt
#-----------------------------------------------
#------THIS CODE IS PART B DATASET 1------------
#-----------------------------------------------

# Define the points
points = [(2, 10), (2, 5), (8, 4), (5, 8), (7, 5), (6, 4), (1, 2), (4, 9)]
dataset = {
    "A1": (2, 10),
    "A2": (2, 5),
    "A3": (8, 4),
    "A4": (5, 8),
    "A5": (7, 5),
    "A6": (6, 4),
    "A7": (1, 2),
    "A8": (4, 9),
}
threshold = 4
# Compute the Euclidean distances between all pairs of points and plot
distances = []
for i in range(len(points)):
    row = []
    for j in range(len(points)):
        dist = math.sqrt((points[i][0]-points[j][0])**2 + (points[i][1]-points[j][1])**2)
        row.append(dist)
    distances.append(row)
fig, ax = plt.subplots()
im = ax.imshow(distances, cmap=plt.cm.Blues)
for i in range(len(points)):
    for j in range(len(points)):
        text = ax.text(j, i, "{:.2f}".format(distances[i][j]), ha="center", va="center", color="w")
ax.set_xticks(range(len(points)))
ax.set_yticks(range(len(points)))
ax.set_xticklabels(["A{}".format(i+1) for i in range(len(points))])
ax.set_yticklabels(["A{}".format(i+1) for i in range(len(points))])
ax.set_title("Euclidean Distances between Points")
fig.tight_layout()
plt.show()

# perform nearest neighbor clustering
clusters = []
for point in dataset:
    assigned_cluster = None
    for cluster in clusters:
        if all(math.sqrt((dataset[point][0] - dataset[other_point][0])**2 + (dataset[point][1] - dataset[other_point][1])**2) <= threshold for other_point in cluster):
            assigned_cluster = cluster
            break
    if assigned_cluster is None:
        clusters.append([point])
    else:
        assigned_cluster.append(point)

# plot the results
colors = ["red", "green", "blue", "purple", "orange", "gray", "pink", "cyan"]
for i, cluster in enumerate(clusters):
    center_x = sum(dataset[point][0] for point in cluster) / len(cluster)
    center_y = sum(dataset[point][1] for point in cluster) / len(cluster)
    
    print('center [', i, ']:', center_x, ',', center_y)
    plt.scatter(center_x, center_y, color=colors[i], marker="x", s=100)
    for point in cluster:
        plt.scatter(dataset[point][0], dataset[point][1], color=colors[i])
plt.show()

print('clusters:', clusters)

from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt
import numpy as np
#-----------------------------------------------
#------THIS CODE IS PART D DATASET 1------------
#-----------------KNN---------------------------
#-----------------------------------------------

# Define the dataset
X = np.array([(2,10), (2,5), (8,4), (5,8), (7,5), (6,4), (1,2), (4,9)])
threshold = 4

# Perform nearest neighbors clustering
nbrs = NearestNeighbors(n_neighbors=len(X), radius=threshold).fit(X)
distances, indices = nbrs.radius_neighbors(X)
centers = [X[index].mean(axis=0) for index in indices]

# Remove duplicate centers
centers = np.unique(np.round(centers, decimals=2), axis=0)

# Plot the clusters with centers marked with "x"
colors = ['red', 'blue', 'green', 'purple', 'orange', 'gray', 'brown', 'pink']
for i, cluster in enumerate(indices):
    plt.scatter(X[cluster][:, 0], X[cluster][:, 1], c=colors[i])
    
for center in centers:
    plt.scatter(center[0], center[1], marker='x', s=100, c='black')
    
plt.show()

print(centers)

from typing import List, Tuple
import numpy as np
import matplotlib.pyplot as plt
import math
#-----------------------------------------------
#------THIS CODE IS PART C DATASET 1------------
#-----------------------------------------------

def euclidean_distance(point1: Tuple[float, float], point2: Tuple[float, float]) -> float:
    x1, y1 = point1
    x2, y2 = point2
    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)

def get_neighbors(point: Tuple[float, float], points: List[Tuple[float, float]], eps: float) -> List[int]:
    neighbors = []
    for i, p in enumerate(points):
        if euclidean_distance(point, p) <= eps:
            neighbors.append(i)
    return neighbors

def dbscan(points: List[Tuple[float, float]], eps: float, min_pts: int) -> List[int]:
    labels = [-1] * len(points)
    cluster_id = 0
    for i, point in enumerate(points):
        if labels[i] != -1:
            continue
        neighbors = get_neighbors(point, points, eps)
        if len(neighbors) < min_pts:
            continue
        cluster_id += 1
        labels[i] = cluster_id
        for j in neighbors:
            if labels[j] == -1:
                labels[j] = cluster_id
                new_neighbors = get_neighbors(points[j], points, eps)
                if len(new_neighbors) >= min_pts:
                    neighbors.extend(new_neighbors)
    return labels

# Define the dataset
points = [(2, 10), (2, 5), (8, 4), (5, 8), (7, 5), (6, 4), (1, 2), (4, 9)]

# Perform DBScan clustering
labels = dbscan(points, eps=4, min_pts=2)

# Plot the results
x = [p[0] for p in points]
y = [p[1] for p in points]
plt.scatter(x, y, c=labels)
plt.title('DBScan Clustering')
plt.xlabel('X-axis')
plt.ylabel('Y-axis')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
#-----------------------------------------------
#------THIS CODE IS PART D DATASET 1------------
#-----------------DBScan------------------------
#-----------------------------------------------


# Define the dataset
X = np.array([[2,10], [2,5], [8,4], [5,8], [7,5], [6,4], [1,2], [4,9]])

# Perform DBScan clustering
dbscan = DBSCAN(eps=4, min_samples=2)
dbscan.fit(X)

# Get the labels and the number of clusters
labels = dbscan.labels_
n_clusters = len(set(labels)) - (1 if -1 in labels else 0)

# Print the results
print('Number of clusters:', n_clusters)
print('Cluster labels:', labels)

# Plot the clusters
plt.scatter(X[:, 0], X[:, 1], c=labels)
plt.xlabel('X')
plt.ylabel('Y')
plt.title('DBScan Clustering')
plt.show()
